{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognition\n",
    "\n",
    "MNIST database consists of hand-written digits of $28\\times 28$ pixels. The images are centered and scaled. The background is black and digits are white.\n",
    "\n",
    "In our data, we use 32000 images for training and 10000 images for testing.\n",
    "\n",
    "We first import packages and basic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as time\n",
    "from skimage.io import imread, imshow, show, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "picture_size = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read data. Data for training is in 'train' folder, and data for testing is in 'test' folder. In an application such as character recognition, we can use grayscale images. Each pixel has a value between 0 and 1 or between 0 and 255 (as it is the case here). A value of 0 corresponds to a black pixel and a value of 255 corresponds to a white pixel.\n",
    "\n",
    "Images in the problem data are $28 \\times 28$ pixels. When using these images we have to reshape them into $1 \\times 784$ features, each representing a pixel. To plot the characters we have to transform the data into a $28 \\times 28$ pixel matrix. \n",
    "\n",
    "In order to understand reading and reshaping data, you can use the code below.\n",
    "\n",
    "In addition to that labels are also provided in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_132    188.0\n",
      "pixel_133    255.0\n",
      "pixel_134     94.0\n",
      "pixel_159    191.0\n",
      "pixel_160    250.0\n",
      "pixel_161    253.0\n",
      "pixel_162     93.0\n",
      "pixel_186    123.0\n",
      "pixel_187    248.0\n",
      "pixel_188    253.0\n",
      "pixel_189    167.0\n",
      "pixel_190     10.0\n",
      "pixel_213     80.0\n",
      "pixel_214    247.0\n",
      "pixel_215    253.0\n",
      "pixel_216    208.0\n",
      "pixel_217     13.0\n",
      "pixel_240     29.0\n",
      "pixel_241    207.0\n",
      "pixel_242    253.0\n",
      "pixel_243    235.0\n",
      "pixel_244     77.0\n",
      "pixel_267     54.0\n",
      "pixel_268    209.0\n",
      "pixel_269    253.0\n",
      "pixel_270    253.0\n",
      "pixel_271     88.0\n",
      "pixel_294     93.0\n",
      "pixel_295    254.0\n",
      "pixel_296    253.0\n",
      "             ...  \n",
      "pixel_487    253.0\n",
      "pixel_488    245.0\n",
      "pixel_489     93.0\n",
      "pixel_513    103.0\n",
      "pixel_514    253.0\n",
      "pixel_515    253.0\n",
      "pixel_516    191.0\n",
      "pixel_540     89.0\n",
      "pixel_541    240.0\n",
      "pixel_542    253.0\n",
      "pixel_543    195.0\n",
      "pixel_544     25.0\n",
      "pixel_567     15.0\n",
      "pixel_568    220.0\n",
      "pixel_569    253.0\n",
      "pixel_570    253.0\n",
      "pixel_571     80.0\n",
      "pixel_595     94.0\n",
      "pixel_596    253.0\n",
      "pixel_597    253.0\n",
      "pixel_598    253.0\n",
      "pixel_599     94.0\n",
      "pixel_623     89.0\n",
      "pixel_624    251.0\n",
      "pixel_625    253.0\n",
      "pixel_626    250.0\n",
      "pixel_627    131.0\n",
      "pixel_652    214.0\n",
      "pixel_653    218.0\n",
      "pixel_654     95.0\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAAEZCAYAAABFOZpTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb3bb470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = np.zeros((1, picture_size*picture_size))\n",
    "\n",
    "img = imread('train/0.png', as_grey=True)\n",
    "img = np.reshape(img, (1,picture_size*picture_size))\n",
    "df_train[0,:]=img\n",
    "\n",
    "df_train=pd.DataFrame(df_train)\n",
    "df_train.columns = ['pixel_' + str(i) for i in range(picture_size*picture_size)]\n",
    "print df_train.iloc[0,:][df_train.iloc[0,:] >0]\n",
    "\n",
    "\n",
    "img = df_train.iloc[0,:]\n",
    "img = np.reshape(img,(picture_size,picture_size))\n",
    "imshow(img/255)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Random Forest and Feature Reduction in to make our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I\n",
    "\n",
    "Use supervised learning for predicting characters.\n",
    "\n",
    "1. Select a supervised learning model\n",
    "2. Use training data for training your model\n",
    "3. Test your model on testing data\n",
    "4. Display your results (accuracy and confusion matrix)\n",
    "5. Report on feature importances, display the important features on a picture such as a heatmap\n",
    "\n",
    "You can use Random Forests, AdaBoost, Gradient Boosting, or Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II\n",
    "\n",
    "Use unsupervised learning by combining it with supervised learning for predicting characters.\n",
    "\n",
    "1. Select an unsupervised learning model. You can use either Principal Component Analysis (sklearn.decomposition.PCA) or Gaussian Mixture Model (sklearn.mixture.GMM) \n",
    "2. Use training data for training your model. Note that you also have to choose the number of components. \n",
    "    * For PCA, you can select 2 components.\n",
    "    * For GMM, select a sufficiently large number (more than 10 as we have 10 classes from 0 to 9, I suggest 50)\n",
    "3. Display your results. \n",
    "    * If you are using PCA, draw a scatter plot with each digit in different color.\n",
    "    * If you are using GMM, you can draw some of the components as pictures. \n",
    "4. Use your result from previous part in a supervised model. Your new input is coordinates of components (for PCA) and probabilities of belonging to components (for GMM)\n",
    "5. Test your model on testing data\n",
    "6. Display your results (accuracy and confusion matrix)\n",
    "7. Compare your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You will be graded by the coherence and quality of your responses. I will not consider the accuracy of your results in grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}